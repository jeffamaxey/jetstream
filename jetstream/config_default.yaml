# ============================== Jetstream ====================================
# Set the logging style. If this is null, the best logger will be chosen from
# the logging profiles below. You can also define custom profiles, see more
# info below.

# Choose the logging profile, if this is null the profile will be chosen based
# on stderr properties (pretty and colorful for ttys, otherwise plain text).
# Choose from options under settings.logging_profiles
log: null

# Set the default backend. Choose from the options listed in settings.backends
backend: local

# This option sets the command that will be used for retrieving log snippets
# It must include a placeholder {path} that will be replaced with the path to
# the log file.
snippet_cmd: tail "{path}"

# If this is set to false, utils.dynamic_import will only search builtins when
# loading functions
dynamic_import: true

# Config data is handled with loaders (for files) and parsers (for data passed
# as arguments). These settings configure the functions that will be used for
# loading or parsing items when given with -c/--config arguments.
loaders:
  csv: jetstream.utils.load_csv
  csv-nh: jetstream.utils.load_csv_nh
  file: jetstream.utils.load_file
  json: jetstream.utils.load_json
  mer: jetstream.utils.load_csv
  tsv: jetstream.utils.load_tsv
  tsv-nh: jetstream.utils.load_tsv_nh
  txt: jetstream.utils.load_txt
  yaml: jetstream.utils.load_yaml
  yml: jetstream.utils.load_yaml

parsers:
  csv: jetstream.utils.parse_csv
  csv-nh: jetstream.utils.parse_csv_nh
  json: jetstream.utils.parse_json
  mer: jetstream.utils.parse_csv
  tsv: jetstream.utils.parse_tsv
  tsv-nh: jetstream.utils.parse_tsv_nh
  txt: jetstream.utils.parse_txt
  yaml: jetstream.utils.parse_yaml
  yml: jetstream.utils.parse_yaml
  url: urllib.parse.urlparse
  uri: urllib.parse.urlparse

# =================================== Runner ==================================
runner:
  # These options control how failures are reported by the runner when
  # a workflow run ends:
  # "report_failures" sets the max number of failed tasks that will be logged
  # when the run ends (use -1 for unlimited).
  # "report_failures_logs" controls whether log snippets will be shown for
  # failed tasks.
  report_failures: 5
  report_failures_logs: true

  # These settings modify the workflow runner internal behaviors. They are not
  # documented well and should be modified with caution. Misconfiguration here
  # can cause CPU over-utilization or deadlock the runner.
  id_format: js{id}
  max_concurrency: null
  throttle: 0.1
  autosave_min: 5
  autosave_max: 60


# ================================== Projects =================================
projects:
  id_format: p{id}
  lock_timeout: 60
  history_max_tries: 10
  history_filename: %Y-%m-%dT%H-%M-%SZ.yaml


# ================================== Backends =================================
# Backends handle the tasks when they are ready to be executed. Each backend
# has its own set of properties that can be modified here.
backends:
  local:
    (): jetstream.backends.local.LocalBackend
    blocking_io_penalty: 30
    cpus: null
  slurm:
    (): jetstream.backends.slurm.SlurmBackend
    job_monitor_max_fails: 5
    sacct_frequency: 10
    sacct_fields:
      - JobID
      - JobName
      - Partition
      - Account
      - AllocCPUS
      - State
      - ExitCode
      - Elapsed
      - ElapsedRaw
      - Start
      - End
      - MaxRSS
  dnanexus:
    (): jetstream.backends.dnanexus.DnanexusBackend
  local_docker:
    (): jetstream.backends.local_docker.LocalDockerBackend
  local_singularity:
    (): jetstream.backends.local_singularity.LocalSingularityBackend
    pullfolder: null
  slurm_singularity:
    (): jetstream.backends.slurm_singularity.SlurmSingularityBackend
    sbatch_account: null
    input_file_validation: False

# This option controls the number of times the runner will attempt to
# submit a job to Slurm before giving up. (Use -1 for unlimited)
slurm_sbatch_retry: 10

# This option controls how the runner will classify a job state.
# For Slurm clusters with automatic resubmit, some job states should
# be considered active that would be inactive on other clusters.
slurm_active_states:
  - CONFIGURING
  - COMPLETING
  - RUNNING
  - PENDING
  - NODE_FAIL

slurm_passed_states:
  - COMPLETED

# ================================== Pipelines ================================
# Pipelines are a collection of pre-built workflows that are installed in the
# pipelines:home directory. They can be run by name using the jetstream
# pipelines command. Users will need to change pipelines:home in order to use
# the pipelines command
pipelines:
  searchpath: ~/


# ================================== Logging ==================================
# To permanently force a single logging style, create a key in your user
# config like this:
#
#   logging: <profile name>
#
# Each key under logging_profiles is a mapping that meets the dictionary
# configuration requirements for the logging module.
# To create a new logging profile, create a new key under the logging_profiles
# section of your user config, the value should be a mapping that meets the
# Python logging dict config schema.
# See: https://docs.python.org/3.7/library/logging.config.html
# Example:
#
# logging_profiles:
#   <profile_name>:
#      version: 1  # Required for future backwards-compatibility
#      # Everything below here follows the Python logging dict config schema
#      formatters:
#        f:
#          format: "[{name}] {asctime}: {message}"
#          datefmt: "%Y-%m-%d %H:%M:%S"
#          style: "{"
#      handlers:
#        h:
#          class: logging.StreamHandler
#          level: INFO
#          formatter: f
#      loggers:
#        jetstream:  # Jetstream modules are all children of this logger
#          level: INFO
#          handlers: [h]
#
logging_profiles:
  silent:
    version: 1
  basic:
    version: 1
    formatters:
      f:
        format: '[{asctime}]: {message}'
        datefmt: '%Y-%m-%d %H:%M:%S'
        style: '{'
    handlers:
      h:
        class: logging.StreamHandler
        level: INFO
        formatter: f
    loggers:
      jetstream:
        level: INFO
        handlers: [h]
  debug:
    version: 1
    formatters:
      f:
        format: '{name}:{lineno} {levelname} {asctime}: {message}'
        datefmt: '%Y-%m-%d %H:%M:%S'
        style: '{'
    handlers:
      h:
        class: logging.StreamHandler
        level: DEBUG
        formatter: f
    loggers:
      jetstream:
        level: DEBUG
        handlers: [h]
  interactive:
    version: 1
    formatters:
      f:
        format: "[\x1b[4m\x1b[92m\U0001F335 {name}\x1b[0m] {asctime} {levelname}: {message}"
        datefmt: '%Y-%m-%d %H:%M:%S'
        style: '{'
    handlers:
      h:
        class: logging.StreamHandler
        level: INFO
        formatter: f
    loggers:
      jetstream:
        level: INFO
        handlers: [h]


# =============================== Notifications ===============================
# Notification settings control how the runner should alert users when
# certain events occur. Here are some examples
#
# notifications:
#  slack:
#    on: [run-fail, task-fail,]
#    credentials:
#
#  email:
#    on: [run-fail, run-complete]
#    host: localhost
#    port: 0
#    from_addrs: ''
#    to_addrs: []  # Project email addresses will be added to this list
#    msg: |
#      <h1>Jetstream Notice for {{ runner.run_id }}</h1>
#
#      {# this will be formatted with the current run context available #}
#      <p>{{ message }}</p>
notifications: null
